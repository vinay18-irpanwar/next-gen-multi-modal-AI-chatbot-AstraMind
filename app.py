import streamlit as st
from dotenv import load_dotenv
import os
from openai_model import chat_openai
from pollinations_model import generate_image_pollinations
from image_qa_model import analyze_image
from voice_input import get_voice_input
from groq_model import chat_groq
from PIL import Image

load_dotenv()

st.set_page_config(page_title="AstraMind", page_icon="ü§ñ", layout="wide")

# --- Sidebar ---
st.sidebar.title("Settings")

# Model selection for text
text_model = st.sidebar.selectbox(
    "Choose Text Model:",
    ["OpenAI", "Gemini", "Groq"]
)

# Language selection for input and backend
language = st.sidebar.selectbox(
    "Select Language",
    ["English", "Hindi", "French", "Spanish"]
)

# Input language hint mapping
language_hint = {
    "English": "Enter your prompt:",
    "Hindi": "‡§Ö‡§™‡§®‡§æ ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§∞‡•á‡§Ç:",
    "French": "Entrez votre message¬†:",
    "Spanish": "Ingrese su mensaje:"
}


# Model selection for image generation
image_model = st.sidebar.selectbox(
    "Choose Image Model:",
    ["Pollinations"]
)
st.title("ü§ñ AstraMind ‚Äì Your Multimodal AI Assistant")

mode = st.sidebar.selectbox(
    "Choose a feature:",
    ["üí¨ Text Chat", "üñºÔ∏è Image Generation", "üñºÔ∏è Image Q&A", "üéôÔ∏è Voice Chat"]
)

# Store chat history in session state
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# --------------- TEXT CHAT ---------------
if mode == "üí¨ Text Chat":
    prompt = st.text_area(language_hint[language], key="text_prompt")
    if st.button("Send", key="send_btn"):
        if prompt.strip():
            if prompt.lower() == "exit":
                st.success("Exited chat.")
            else:
                if text_model == "OpenAI":
                    response = chat_openai(prompt) 
                elif text_model == "Gemini":
                    from gemini_model import chat_gemini
                    response = chat_gemini(prompt, language=language)
                elif text_model == "Groq":
                    response = chat_groq(prompt, language=language)

                # Append user and bot messages to chat history (do not display history)
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                st.session_state.chat_history.append({"role": "bot", "content": response})

                st.write("### üß† AstraMind Says:")
                st.write(response)
        else:
            st.warning(language_hint[language])

# --------------- IMAGE GENERATION ---------------
elif mode == "üñºÔ∏è Image Generation":
    prompt = st.text_input("Enter an image description:")
    if st.button("Generate Image"):
        if prompt.strip():
            image_url = generate_image_pollinations(prompt)
            st.image(image_url, caption=prompt)
        else:
            st.warning("Please enter a description.")

# --------------- IMAGE Q&A ---------------
elif mode == "üñºÔ∏è Image Q&A":
    uploaded_img = st.file_uploader("Upload an image", type=["jpg", "jpeg", "png"])
    question = st.text_input("Ask a question about the image:")
    if st.button("Analyze Image"):
        if uploaded_img and question.strip():
            with open("temp_image.png", "wb") as f:
                f.write(uploaded_img.read())
            result = analyze_image("temp_image.png", question)
            st.image("temp_image.png", caption="Uploaded Image")
            st.write("### üß† Analysis Result:")
            st.write(result)
        else:
            st.warning("Please upload an image and ask a question.")

# --------------- VOICE CHAT ---------------
elif mode == "üéôÔ∏è Voice Chat":
    st.info("üé§ " + language_hint[language])
    uploaded_file = st.file_uploader("Upload your voice file", type=["wav", "mp3"])
    voice_text = None

    if uploaded_file is not None:
        import tempfile
        import speech_recognition as sr

        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(uploaded_file.read())
            tmp_path = tmp.name

        # Recognize speech
        recognizer = sr.Recognizer()
        with sr.AudioFile(tmp_path) as source:
            audio = recognizer.record(source)
        try:
            voice_text = recognizer.recognize_google(audio)
        except sr.UnknownValueError:
            voice_text = "‚ö†Ô∏è Could not understand audio."
        except sr.RequestError:
            voice_text = "‚ö†Ô∏è Google Speech Recognition service error."
        except Exception as e:
            voice_text = f"‚ö†Ô∏è Error: {str(e)}"

    if voice_text:
        st.write(f"üó£Ô∏è {language_hint[language]} {voice_text}")
        if "‚ö†Ô∏è" not in voice_text:
            if text_model == "OpenAI":
                response = chat_openai(voice_text)
            elif text_model == "Gemini":
                from models.gemini_model import chat_gemini
                response = chat_gemini(voice_text, language=language)
            elif text_model == "Groq":
                response = chat_groq(voice_text, language=language)

            # Append user and bot messages to chat history (do not display history)
            st.session_state.chat_history.append({"role": "user", "content": voice_text})
            st.session_state.chat_history.append({"role": "bot", "content": response})

            st.write("### üß† AstraMind Says:")

            st.write(response)

